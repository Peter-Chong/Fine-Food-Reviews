{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_csv('../Reviews.csv')\n",
    "all_df = all_df[['Score', 'Text']]\n",
    "all_df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews = all_df[all_df.Score == 5]\n",
    "negative_reviews = all_df[all_df.Score != 5]\n",
    "\n",
    "positive_reviews = positive_reviews['Text'].astype(str).values.tolist()\n",
    "negative_reviews = negative_reviews['Text'].astype(str).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into two pieces, one for training and one for testing (validation set) \n",
    "pos_cutoff = int(len(positive_reviews)*0.8)\n",
    "neg_cutoff = int(len(negative_reviews)*0.8)\n",
    "\n",
    "test_pos = positive_reviews[pos_cutoff:]\n",
    "train_pos = positive_reviews[:pos_cutoff]\n",
    "test_neg = negative_reviews[neg_cutoff:]\n",
    "train_neg = negative_reviews[:neg_cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_pos + train_neg \n",
    "test_x = test_pos + test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine positive and negative labels\n",
    "train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
    "test_y = np.append(np.ones(len(test_pos)), np.zeros(len(test_neg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y.shape = (314940,)\n",
      "test_y.shape = (78735,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape train and test sets\n",
    "print(\"train_y.shape = \" + str(train_y.shape))\n",
    "print(\"test_y.shape = \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing  \n",
    "### Stemming, remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_review(review):\n",
    "    \"\"\"Process review function.\n",
    "    Input:\n",
    "        review: a string containing a review\n",
    "    Output:\n",
    "        reviews_clean: a list of words containing the processed review\n",
    "    \"\"\"\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    \n",
    "    # remove html tags like <br />\n",
    "    review = re.sub(r'<.*?>', ' ', review) # .* is for greedy and .*? makes it not greedy\n",
    "    # remove --- or --\n",
    "    review = re.sub(r'---', ' ', review)\n",
    "    review = re.sub(r'--', ' ', review)\n",
    "    # remove numbers\n",
    "    review = re.sub(r'[0-9]', '', review)\n",
    "    # remove #\n",
    "    review = re.sub(r'#', '', review)\n",
    "    \n",
    "    # tokenize review\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "    review_tokens = tokenizer.tokenize(review)\n",
    "\n",
    "    reviews_clean = []\n",
    "    for word in review_tokens:\n",
    "        if (word not in stopwords_english and  # remove stopwords\n",
    "                word not in string.punctuation):  # remove punctuation\n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            reviews_clean.append(stem_word)\n",
    "\n",
    "    return reviews_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_freqs(reviews, ys):\n",
    "    \"\"\"Build frequencies.\n",
    "    Input:\n",
    "        reviews: a list of reviews\n",
    "        ys: an m x 1 array with the sentiment label of each review\n",
    "            (either 0 or 1)\n",
    "    Output:\n",
    "        freqs: a dictionary mapping each (word, sentiment) pair to its frequency\n",
    "    \"\"\"\n",
    "    freqs = {}\n",
    "    for y, review in zip(ys, reviews):\n",
    "        for word in process_review(review):\n",
    "            pair = (word, y)\n",
    "            freqs[pair] = freqs.get(pair, 0) + 1\n",
    "            \n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = build_freqs(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a freqs dictionary, `train_x` (a list of reviews) and a `train_y` (a list of labels for each review), implement a naive bayes classifier.\n",
    "\n",
    "#####  $V$\n",
    "- The number of unique words that appear in the `freqs` dictionary to get $V$.\n",
    "\n",
    "#####  $freq_{pos}$ and $freq_{neg}$\n",
    "- By using `freqs` dictionary, we can compute the positive and negative frequency of each word $freq_{pos}$ and $freq_{neg}$.\n",
    "\n",
    "#####  $N_{pos}$ and $N_{neg}$\n",
    "- By using `freqs` dictionary, we can also compute the total number of positive words and total number of negative words $N_{pos}$ and $N_{neg}$.\n",
    "\n",
    "#####  $D$, $D_{pos}$, $D_{neg}$\n",
    "- By using the `train_y` input list of labels, calculate the number of documents (reviews) $D$, as well as the number of positive documents (reviews) $D_{pos}$ and number of negative documents (reviews) $D_{neg}$.\n",
    "- Calculate the probability that a document (review) is positive $P(D_{pos})$, and the probability that a document (review) is negative $P(D_{neg})$\n",
    "\n",
    "#####  logprior\n",
    "- the logprior is $log(D_{pos}) - log(D_{neg})$\n",
    "\n",
    "#####  log likelihood\n",
    "- Finally, we can iterate over each word in the vocabulary, use out `lookup` function to get the positive frequencies, $freq_{pos}$, and the negative frequencies, $freq_{neg}$, for that specific word.\n",
    "- Compute the positive probability of each word $P(W_{pos})$, negative probability of each word $P(W_{neg})$ using equations 4 & 5.\n",
    "\n",
    "$$ P(W_{pos}) = \\frac{freq_{pos} + 1}{N_{pos} + V}\\tag{4} $$\n",
    "$$ P(W_{neg}) = \\frac{freq_{neg} + 1}{N_{neg} + V}\\tag{5} $$\n",
    "\n",
    "- We can then compute the loglikelihood: $log \\left( \\frac{P(W_{pos})}{P(W_{neg})} \\right)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(freqs, train_x, train_y):\n",
    "    '''\n",
    "    Input:\n",
    "        freqs: dictionary from (word, label) to how often the word appears\n",
    "        train_x: a list of reviews\n",
    "        train_y: a list of labels correponding to the reviews (0,1)\n",
    "    Output:\n",
    "        logprior: the log prior\n",
    "        loglikelihood: the log likelihood of Naive bayes equation\n",
    "    '''\n",
    "    loglikelihood = {}\n",
    "    logprior = 0\n",
    "\n",
    "    # calculate V, the number of unique words in the vocabulary\n",
    "    vocab = set([pair[0] for pair in freqs.keys()])\n",
    "    V = len(vocab)\n",
    "\n",
    "    # calculate N_pos and N_neg\n",
    "    N_pos = N_neg = 0\n",
    "    for pair in freqs.keys():\n",
    "        if pair[1] > 0:\n",
    "            N_pos += freqs[pair]\n",
    "        else:\n",
    "            N_neg += freqs[pair]\n",
    "\n",
    "    # Calculate D, the number of documents\n",
    "    D = len(train_y)\n",
    "\n",
    "    # Calculate D_pos, the number of positive documents\n",
    "    D_pos = sum(train_y)\n",
    "\n",
    "    # Calculate D_neg, the number of negative documents\n",
    "    D_neg = D - D_pos\n",
    "\n",
    "    # Calculate logprior\n",
    "    logprior = np.log(D_pos) - np.log(D_neg)\n",
    "\n",
    "    for word in vocab:\n",
    "        # get the positive and negative frequency of the word\n",
    "        freq_pos = freqs.get((word, 1), 0)\n",
    "        freq_neg = freqs.get((word, 0), 0)\n",
    "\n",
    "        # calculate the probability that each word is positive, and negative\n",
    "        p_w_pos = (freq_pos + 1)/(N_pos + V)\n",
    "        p_w_neg = (freq_neg + 1)/(N_neg + V)\n",
    "\n",
    "        # calculate the log likelihood of the word\n",
    "        loglikelihood[word] = np.log(p_w_pos/p_w_neg)\n",
    "\n",
    "    return logprior, loglikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprior, loglikelihood = train_naive_bayes(freqs, train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_predict(review, logprior, loglikelihood):\n",
    "    '''\n",
    "    Input:\n",
    "        review: a string\n",
    "        logprior: a number\n",
    "        loglikelihood: a dictionary of words mapping to numbers\n",
    "    Output:\n",
    "        p: the sum of all the logliklihoods of each word in the review (if found in the dictionary) + logprior (a number)\n",
    "\n",
    "    '''\n",
    "    # process the review to get a list of words\n",
    "    word_l = process_review(review)\n",
    "\n",
    "    # initialize probability to zero\n",
    "    p = 0\n",
    "\n",
    "    # add the logprior\n",
    "    p += logprior\n",
    "\n",
    "    for word in word_l:\n",
    "        # check if the word exists in the loglikelihood dictionary\n",
    "        if word in loglikelihood:\n",
    "            # add the log likelihood of that word to the probability\n",
    "            p += loglikelihood[word]\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_bayes(test_x, logprior, loglikelihood):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        test_x: A list of reviews\n",
    "        logprior: the logprior\n",
    "        loglikelihood: a dictionary with the loglikelihoods for each word\n",
    "    Output:\n",
    "        y_hat: the predictions\n",
    "    \"\"\"\n",
    "    y_hats = []\n",
    "    \n",
    "    for review in test_x:\n",
    "        y_hat_i = 1 if naive_bayes_predict(review, logprior, loglikelihood) > 0 else 0\n",
    "        \n",
    "        # append the predicted class to the list y_hats\n",
    "        y_hats.append(y_hat_i)\n",
    "\n",
    "    return y_hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = test_naive_bayes(test_x, logprior, loglikelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(test_y, y_hat):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        test_y: (m, 1) vector with the corresponding labels for the list of reviews\n",
    "        y_hat: the predictions\n",
    "    Output:\n",
    "        accuracy: (# of reviews classified correctly) / (total # of reviews)\n",
    "        precision: TP/(TP+FP)\n",
    "        recall: TP/(TP+FN)\n",
    "        f1_score: 2*(precision*recall)/(precision+recall)\n",
    "    \"\"\"\n",
    "    test_y = pd.Series(test_y, name='Actual')\n",
    "    y_hat = pd.Series(y_hat, name='Predicted')\n",
    "\n",
    "    confusion = pd.crosstab(test_y, y_hat) \n",
    "    tn = confusion[0][0]\n",
    "    fn = confusion[0][1]\n",
    "    fp = confusion[1][0]\n",
    "    tp = confusion[1][1]\n",
    "    \n",
    "    accuracy = (tn+tp)/(tn+tp+fp+fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1_score = 2*(precision*recall)/(precision+recall)\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive bayes model's accuracy = 0.7927\n",
      "Naive bayes model's precision = 0.8167\n",
      "Naive bayes model's recall = 0.8697\n",
      "Naive bayes model's f1-score = 0.8424\n"
     ]
    }
   ],
   "source": [
    "scores = scoring(test_y, y_hat)\n",
    "print(f\"Naive bayes model's accuracy = {scores[0]:.4f}\")\n",
    "print(f\"Naive bayes model's precision = {scores[1]:.4f}\")\n",
    "print(f\"Naive bayes model's recall = {scores[2]:.4f}\")\n",
    "print(f\"Naive bayes model's f1-score = {scores[3]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict my own review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['food', 'tast', 'meh']\n",
      "-0.6344431419568566\n",
      "Negative sentiment\n"
     ]
    }
   ],
   "source": [
    "my_review = 'This food tasted meh'\n",
    "print(process_review(my_review))\n",
    "y_pred = naive_bayes_predict(my_review, logprior, loglikelihood)\n",
    "print(y_pred)\n",
    "if y_pred > 0:\n",
    "    print('Positive sentiment')\n",
    "else: \n",
    "    print('Negative sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
